{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.optim import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle \n",
    "import time \n",
    "import imageio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trajectories: 5\n"
     ]
    }
   ],
   "source": [
    "data_path = \"expert_data/human_demos_5_435.0.pkl\"\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    trajs = pickle.load(f)\n",
    "\n",
    "print(f\"Number of trajectories: {len(trajs)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 3, 96, 96), (5000, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states=[]\n",
    "actions=[]\n",
    "for traj in trajs:\n",
    "    for state,action in traj:\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "\n",
    "states=np.array(states, dtype=np.float32)\n",
    "actions=np.array(actions, dtype=np.float32)\n",
    "\n",
    "states = np.transpose(states, (0,3,1,2))\n",
    "states.shape,actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 3, 96, 96]), torch.Size([64, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = torch.utils.data.DataLoader( list(zip(states, actions)), batch_size=64, shuffle=True)\n",
    "\n",
    "batch=next(iter(data_loader))\n",
    "states,actions = batch\n",
    "states.shape,actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State dim: torch.Size([3, 96, 96]), Action dim: 3\n"
     ]
    }
   ],
   "source": [
    "action_dim=actions.shape[1]\n",
    "state_dim=states.shape[1:]\n",
    "print(f\"State dim: {state_dim}, Action dim: {action_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Fe(nn.Module):\n",
    "    def __init__(self, fe_dim=512):\n",
    "        super(CNN_Fe, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(8 * 8 * 64, fe_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegNet(CNN_Fe):\n",
    "    def __init__(self, action_dim, fe_dim=512):\n",
    "        super(RegNet, self).__init__(fe_dim)\n",
    "        self.decoder = nn.Linear(fe_dim, action_dim)\n",
    "    def forward(self,x):\n",
    "        fe=super().forward(x) \n",
    "        x = self.decoder(fe)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = RegNet(action_dim=action_dim)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(bc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.5746\n",
      "Epoch 25 Loss: 0.0031\n",
      "Epoch 50 Loss: 0.0021\n",
      "Epoch 75 Loss: 0.0017\n",
      "Epoch 100 Loss: 0.0013\n",
      "Epoch 125 Loss: 0.0011\n",
      "Epoch 150 Loss: 0.0007\n",
      "Epoch 175 Loss: 0.0004\n",
      "Epoch 200 Loss: 0.0002\n",
      "Epoch 225 Loss: 0.0002\n",
      "Epoch 250 Loss: 0.0001\n",
      "Epoch 275 Loss: 0.0001\n",
      "Epoch 300 Loss: 0.0001\n",
      "Epoch 325 Loss: 0.0001\n",
      "Epoch 350 Loss: 0.0001\n",
      "Epoch 375 Loss: 0.0000\n",
      "Epoch 400 Loss: 0.0000\n",
      "Epoch 425 Loss: 0.0000\n",
      "Epoch 450 Loss: 0.0000\n",
      "Epoch 475 Loss: 0.0001\n",
      "Epoch 500 Loss: 0.0001\n",
      "\n",
      "Training time: 13.60 min\n"
     ]
    }
   ],
   "source": [
    "st=time.time()\n",
    "loss_list = []\n",
    "test_loss = [] \n",
    "n_epoch = 5_00\n",
    " \n",
    "for itr in range(0, n_epoch+1):\n",
    "    total_loss = 0\n",
    "    b=0\n",
    "    for batch_states, batch_actions in data_loader: \n",
    "        y_pred = bc(batch_states.float())\n",
    "        loss   = criterion(y_pred, batch_actions) \n",
    "        total_loss += loss.item() \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b += 1 \n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    if itr % (n_epoch//20)==0:\n",
    "        print(f'Epoch {itr} Loss: {total_loss/b:.4f}')\n",
    "\n",
    "et=time.time()\n",
    "mt=(et-st)/60\n",
    "print(f\"\\nTraining time: {mt:.2f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name=\"CarRacing-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.eval()\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_an_episode(env_name, model, video_path=None, max_steps=1000):\n",
    "    video_writer=None \n",
    "    if video_path is not None:\n",
    "        print(f'Saving video to {video_path}')\n",
    "        video_writer = imageio.get_writer(video_path, fps=20)\n",
    "        env=gym.make(env_name, render_mode='rgb_array')\n",
    "    else:\n",
    "        env=gym.make(env_name)\n",
    "\n",
    "    obs,_=env.reset()\n",
    "    rewards=0\n",
    "    step=0\n",
    "    for _ in range(max_steps):\n",
    "        step+=1\n",
    "        state=obs[None,:]\n",
    "        state=np.transpose(state, (0,3,1,2))\n",
    "        state=torch.tensor(state, dtype=torch.float32)\n",
    "        pred=model(state).detach().numpy()[0]\n",
    "        obs, reward, done, trunc,_ = env.step(pred)\n",
    "\n",
    "        if video_path is not None:\n",
    "            image=env.render()\n",
    "            video_writer.append_data(image)\n",
    "\n",
    "        rewards+=reward\n",
    "        if done or trunc:\n",
    "            break\n",
    "\n",
    "    if video_path is not None:\n",
    "        video_writer.close()\n",
    "    return {'reward':rewards, 'step':step-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode #0 reward: 470.42\n",
      "episode #1 reward: 271.07\n",
      "episode #2 reward: 377.74\n",
      "episode #3 reward: 475.44\n",
      "episode #4 reward: 493.41\n",
      "episode #5 reward: 242.28\n",
      "episode #6 reward: 475.97\n",
      "episode #7 reward: 381.73\n",
      "episode #8 reward: 467.47\n",
      "episode #9 reward: 450.68\n",
      "episode #10 reward: 483.63\n",
      "episode #11 reward: 458.22\n",
      "episode #12 reward: 329.94\n",
      "episode #13 reward: 257.38\n",
      "episode #14 reward: 443.33\n",
      "episode #15 reward: 413.99\n",
      "episode #16 reward: 390.68\n",
      "episode #17 reward: 329.04\n",
      "episode #18 reward: 414.29\n",
      "episode #19 reward: 404.53\n",
      "\n",
      " score: 401.56 +- 76.68\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "n_trajectory=20\n",
    "for i in range(n_trajectory):\n",
    "    stats=play_an_episode(env_name, bc)\n",
    "    rewards=stats['reward']\n",
    "    print(f'episode #{i} reward: {rewards:0.2f}')\n",
    "    scores.append(rewards)\n",
    "\n",
    "print(f'\\n score: {np.mean(scores):0.2f} +- {np.std(scores):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's render and save a video using the learned policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to bc_carracing.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "[swscaler @ 0x5fac480] Warning: data is not aligned! This can lead to a speed loss\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reward': 446.7625899280513, 'step': 999}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats=play_an_episode(env_name, bc, video_path='bc_carracing.mp4')\n",
    "stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"bc_carracing.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video('bc_carracing.mp4' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

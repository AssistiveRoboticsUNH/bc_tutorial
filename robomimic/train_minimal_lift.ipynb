{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import robomimic\n",
    "import robomimic.utils.file_utils as FileUtils\n",
    "import robomimic.utils.env_utils as EnvUtils\n",
    "import robomimic.utils.obs_utils as ObsUtils\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.optim import Adam \n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device= torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Robomimic Lift Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of demos: 200\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"/home/ns/robomimic/datasets/lift/ph/low_dim_v141.hdf5\"\n",
    "f = h5py.File(dataset_path, \"r\")\n",
    "demos = list(f[\"data\"].keys())\n",
    "num_demos = len(demos)\n",
    "print(f'Number of demos: {num_demos}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_keys=['object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1042, 19), (1042, 7))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we will use a small dataset of first 20 demonstration for faster training\n",
    "n_demo=20\n",
    "actions_list=[]\n",
    "obs_list=[]\n",
    "for i in range(n_demo):\n",
    "    demo_id='demo_{}'.format(i)\n",
    "    traj=f['data'][demo_id]\n",
    " \n",
    "    actions=traj['actions']\n",
    "    select_obs=np.hstack( [traj['obs'][key] for key in select_keys] ) \n",
    "    actions_list.append(actions)\n",
    "    obs_list.append(select_obs)\n",
    "\n",
    "actions_list=np.concatenate(actions_list)\n",
    "obs_list=np.concatenate(obs_list)\n",
    "obs_list.shape, actions_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 19]), torch.Size([64, 7]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader( list(zip(obs_list, actions_list)), batch_size=64, shuffle=True)\n",
    "\n",
    "batch=next(iter(data_loader))\n",
    "states,actions = batch\n",
    "states.shape,actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 7\n"
     ]
    }
   ],
   "source": [
    "action_dim=actions.shape[1]\n",
    "state_dim=states.shape[1]\n",
    "print(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, size=32):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim,size),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(size,size),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "    \n",
    "class RegNet(MLP):\n",
    "    def __init__(self, input_dim , size, action_dim):\n",
    "        super(RegNet, self).__init__(input_dim, size)\n",
    "        self.decoder = nn.Linear(size, action_dim)\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "bc = RegNet(state_dim, 64, action_dim)\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = Adam(bc.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.2145\n",
      "Epoch 150 Loss: 0.0586\n",
      "Epoch 300 Loss: 0.0367\n",
      "Epoch 450 Loss: 0.0339\n",
      "Epoch 600 Loss: 0.0314\n",
      "Epoch 750 Loss: 0.0304\n",
      "Epoch 900 Loss: 0.0290\n",
      "Epoch 1050 Loss: 0.0282\n",
      "Epoch 1200 Loss: 0.0257\n",
      "Epoch 1350 Loss: 0.0250\n",
      "Epoch 1500 Loss: 0.0232\n",
      "Epoch 1650 Loss: 0.0223\n",
      "Epoch 1800 Loss: 0.0211\n",
      "Epoch 1950 Loss: 0.0208\n",
      "Epoch 2100 Loss: 0.0198\n",
      "Epoch 2250 Loss: 0.0202\n",
      "Epoch 2400 Loss: 0.0187\n",
      "Epoch 2550 Loss: 0.0184\n",
      "Epoch 2700 Loss: 0.0188\n",
      "Epoch 2850 Loss: 0.0179\n",
      "Epoch 3000 Loss: 0.0170\n"
     ]
    }
   ],
   "source": [
    "loss_list = [] \n",
    "n_epoch = 3_000\n",
    " \n",
    "for itr in range(0, n_epoch+1):\n",
    "    total_loss = 0\n",
    "    b=0\n",
    "    for batch_states, batch_actions in data_loader: \n",
    "        y_pred = bc(batch_states.float())\n",
    "        loss   = criterion(y_pred, batch_actions.float()) \n",
    "        total_loss += loss.item() \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        b += 1 \n",
    "        \n",
    "        loss_list.append(loss.item())\n",
    "        \n",
    "    if itr % (n_epoch//20)==0:\n",
    "        print(f'Epoch {itr} Loss: {total_loss/b:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_meta={'env_name': 'Lift',\n",
    " 'type': 1,\n",
    " 'env_kwargs': {'has_renderer': False,\n",
    "  'has_offscreen_renderer': False,\n",
    "  'ignore_done': True,\n",
    "  'use_object_obs': True,\n",
    "  'use_camera_obs': False,\n",
    "  'control_freq': 20,\n",
    "  'controller_configs': {'type': 'OSC_POSE',\n",
    "   'input_max': 1,\n",
    "   'input_min': -1,\n",
    "   'output_max': [0.05, 0.05, 0.05, 0.5, 0.5, 0.5],\n",
    "   'output_min': [-0.05, -0.05, -0.05, -0.5, -0.5, -0.5],\n",
    "   'kp': 150,\n",
    "   'damping': 1,\n",
    "   'impedance_mode': 'fixed',\n",
    "   'kp_limits': [0, 300],\n",
    "   'damping_limits': [0, 10],\n",
    "   'position_limits': None,\n",
    "   'orientation_limits': None,\n",
    "   'uncouple_pos_ori': True,\n",
    "   'control_delta': True,\n",
    "   'interpolation': None,\n",
    "   'ramp_ratio': 0.2},\n",
    "  'robots': ['Panda'],\n",
    "  'camera_depths': False,\n",
    "  'camera_heights': 84,\n",
    "  'camera_widths': 84,\n",
    "  'reward_shaping': False}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[robosuite WARNING] No private macro file found! (macros.py:53)\n",
      "[robosuite WARNING] It is recommended to use a private macro file (macros.py:54)\n",
      "[robosuite WARNING] To setup, run: python /home/ns/robosuite/robosuite/scripts/setup_macros.py (macros.py:55)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created environment with name Lift\n",
      "Action size is 7\n",
      "ROBOMIMIC WARNING(\n",
      "    No environment version found in dataset!\n",
      "    Cannot verify if dataset and installed environment versions match\n",
      ")\n",
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['robot0_eef_pos']\n",
      "using obs modality: rgb with keys: []\n"
     ]
    }
   ],
   "source": [
    "env = EnvUtils.create_env_from_metadata(\n",
    "    env_meta=env_meta, \n",
    "    render=False,            # no on-screen rendering\n",
    "    render_offscreen=True,   # off-screen rendering to support rendering video frames\n",
    ")\n",
    "dummy_spec = dict(  obs=dict( low_dim=[\"robot0_eef_pos\"], rgb=[], ),)\n",
    "ObsUtils.initialize_obs_utils_with_obs_specs(obs_modality_specs=dummy_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(env, rollout_horizon = 400, video_path=None):\n",
    "    total_reward=0 \n",
    "    select_keys=['object', 'robot0_eef_pos', 'robot0_eef_quat', 'robot0_gripper_qpos']\n",
    "\n",
    "    obs = env.reset()\n",
    "    state_dict = env.get_state()\n",
    "    # hack that is necessary for robosuite tasks for deterministic action playback\n",
    "    # obs = env.reset_to(state_dict)\n",
    "\n",
    "    if video_path is not None:\n",
    "        video_writer = imageio.get_writer(video_path, fps=20)\n",
    "        print(f\"Writing video to {video_path}\")\n",
    "    camera_names=[\"agentview\"]\n",
    "\n",
    "    for step_i in range(rollout_horizon):\n",
    "        select_obs=np.hstack( [obs[key] for key in select_keys] ) \n",
    "        state=torch.from_numpy(select_obs).float()\n",
    "        # state=state.to(device='cuda')\n",
    "\n",
    "        act = bc(state).detach().cpu().numpy()\n",
    "        next_obs, r, done, _ = env.step(act)\n",
    "\n",
    "        # compute reward\n",
    "        total_reward += r\n",
    "        success = env.is_success()[\"task\"]\n",
    "\n",
    "        if video_path is not None:\n",
    "            video_img = env.render(mode=\"rgb_array\", height=512, width=512, camera_name=\"agentview\")\n",
    "            video_writer.append_data(video_img)\n",
    "\n",
    "\n",
    "        # break if done or if success\n",
    "        if done or success:\n",
    "            # print(f'stop: done={done} success={success}')\n",
    "            break\n",
    "\n",
    "        # update for next iter\n",
    "        obs = deepcopy(next_obs)\n",
    "\n",
    "    if video_path is not None:\n",
    "        video_writer.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rollout 0 Success: 1.0\n",
      "Rollout 1 Success: 1.0\n",
      "Rollout 2 Success: 1.0\n",
      "Rollout 3 Success: 1.0\n",
      "Rollout 4 Success: 1.0\n",
      "Rollout 5 Success: 1.0\n",
      "Rollout 6 Success: 1.0\n",
      "Rollout 7 Success: 1.0\n",
      "Rollout 8 Success: 1.0\n",
      "Rollout 9 Success: 1.0\n",
      "Rollout 10 Success: 1.0\n",
      "Rollout 11 Success: 1.0\n",
      "Rollout 12 Success: 1.0\n",
      "Rollout 13 Success: 1.0\n",
      "Rollout 14 Success: 1.0\n",
      "Rollout 15 Success: 1.0\n",
      "Rollout 16 Success: 1.0\n",
      "Rollout 17 Success: 1.0\n",
      "Rollout 18 Success: 1.0\n",
      "Rollout 19 Success: 1.0\n",
      "\n",
      "Average Reward: 1.00\n"
     ]
    }
   ],
   "source": [
    "n_rollout=20\n",
    "s=0\n",
    "for i in range(n_rollout):\n",
    "    r=rollout(env, video_path=None)\n",
    "    s+=r\n",
    "    print(f'Rollout {i} Success: {r}')\n",
    "\n",
    "print(f'\\nAverage Reward: {s/n_rollout:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing video to lift_bc.mp4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=rollout(env, video_path=\"lift_bc.mp4\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import time \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import time\n",
    "import gym \n",
    "import pickle  \n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.transformed_distribution import TransformedDistribution\n",
    "from torch.distributions.transforms import TanhTransform\n",
    "from torch.optim import Adam\n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='Ant-v3'\n",
    "data_path = \"/home/ns/bc_tutorial/mujoco/expert_data/Ant-v3_10_3765.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expert data loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10000, 111), (10000, 8), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(data_path, \"rb\") as f:\n",
    "    data_good = pickle.load(f)\n",
    "print('expert data loaded')\n",
    "\n",
    "data_good=data_good[:20]\n",
    "\n",
    "good_obs=[]\n",
    "good_acts=[]\n",
    "good_rews=[]\n",
    "\n",
    "for traj in data_good: \n",
    "    s,a,r=traj  \n",
    "\n",
    "    good_obs.append(s)\n",
    "    good_acts.append(a)\n",
    "    good_rews.append(r)\n",
    "\n",
    "good_obs=np.vstack(good_obs)\n",
    "good_acts=np.vstack(good_acts)\n",
    "good_rews=np.vstack(good_rews) \n",
    "\n",
    "good_obs.shape, good_acts.shape, good_rews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 111]), torch.Size([64, 8]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = DataLoader( list(zip(good_obs, good_acts)), batch_size=64, shuffle=True)\n",
    "\n",
    "batch=next(iter(data_loader))\n",
    "states,actions = batch\n",
    "states.shape,actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 8\n"
     ]
    }
   ],
   "source": [
    "action_dim=actions.shape[1]\n",
    "state_dim=states.shape[1]\n",
    "print(state_dim, action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, size=32):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim,size),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(size,size),\n",
    "            nn.ReLU() \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    " \n",
    "class GaussianPolicy(MLP):\n",
    "    def __init__(self, input_dim, output_dim, hidden_size=64):\n",
    "        super(GaussianPolicy, self).__init__(input_dim, hidden_size) \n",
    "        self.mean = nn.Linear(hidden_size, output_dim) \n",
    "        self.log_std_layer = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self.net(state)\n",
    "        mean = self.mean(x) \n",
    "        log_std = self.log_std_layer(x)  # Predict log_std using a linear layer\n",
    "        std = torch.exp(log_std)\n",
    "\n",
    "        return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "policy = GaussianPolicy(state_dim, action_dim, 64)\n",
    "optimizer = Adam(policy.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 5.723\n",
      "Epoch 50 Loss: -8.211\n",
      "Epoch 100 Loss: -9.187\n",
      "Epoch 150 Loss: -9.694\n",
      "Epoch 200 Loss: -10.009\n",
      "Epoch 250 Loss: -10.226\n",
      "Epoch 300 Loss: -10.415\n",
      "Epoch 350 Loss: -10.564\n",
      "Epoch 400 Loss: -10.686\n",
      "Epoch 450 Loss: -10.789\n",
      "Epoch 500 Loss: -10.881\n",
      "Epoch 550 Loss: -10.978\n",
      "Epoch 600 Loss: -11.039\n",
      "Epoch 650 Loss: -11.108\n",
      "Epoch 700 Loss: -11.171\n",
      "Epoch 750 Loss: -11.241\n",
      "Epoch 800 Loss: -11.302\n",
      "Epoch 850 Loss: -11.321\n",
      "Epoch 900 Loss: -11.374\n",
      "Epoch 950 Loss: -11.428\n"
     ]
    }
   ],
   "source": [
    "num_epochs=1_000\n",
    "for epoch in range(num_epochs): \n",
    "    total_loss=0\n",
    "    b=0\n",
    "    for states, actions in data_loader: \n",
    "        means, stds = policy(states.float())\n",
    "        dist = Normal(means, stds)\n",
    "        log_probs = dist.log_prob(actions).sum(dim=-1)\n",
    "        loss = -log_probs.mean()\n",
    "\n",
    "        total_loss += loss.item() \n",
    "        b=b+1\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % (num_epochs//20)==0:\n",
    "        print(f'Epoch {epoch} Loss: {total_loss/b:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Ant-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/ns/anaconda3/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:190: UserWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "obs,info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23851806, -0.00702067,  0.14628345, -0.16866887, -0.28914148,\n",
       "        0.5216701 ,  0.49675786,  0.39905754], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states=torch.Tensor(obs[None]).to(device)\n",
    "means, stds = policy(states.float())\n",
    "means = means.detach().cpu().numpy()[0]\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(env, policy, is_close=True, is_render=True, max_step=1000): \n",
    "    obs,info = env.reset()\n",
    "    dones=False\n",
    "    total_r=0\n",
    "    step=0\n",
    "    while not dones: \n",
    "        step+=1\n",
    "        states=torch.Tensor(obs[None]).to(device)\n",
    "        means, stds = policy(states.float())\n",
    "        action = means.detach().cpu().numpy()[0]\n",
    "\n",
    "        obs, rewards, done, s, info = env.step(action)\n",
    "        total_r +=rewards  \n",
    "        if done:\n",
    "            break\n",
    "        if step>max_step:\n",
    "            # print('max step reached')\n",
    "            break\n",
    "        # elif s:\n",
    "        #     print('solved!')\n",
    "        #     break\n",
    "    if is_close:\n",
    "        env.close()\n",
    "    return {'reward':total_r, 'step':step-1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/anaconda3/lib/python3.9/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Ant-v3 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.warn(\n",
      "/home/ns/anaconda3/lib/python3.9/site-packages/gym/envs/mujoco/mujoco_env.py:190: UserWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reward': 4024.132919545349, 'step': 1000}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "play(env, policy, is_close=True, is_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode #0 reward: 4197.10\n",
      "episode #1 reward: 3882.40\n",
      "episode #2 reward: 3827.77\n",
      "episode #3 reward: 4166.81\n",
      "episode #4 reward: 4138.98\n",
      "episode #5 reward: 4141.73\n",
      "episode #6 reward: 4120.49\n",
      "episode #7 reward: 4196.64\n",
      "episode #8 reward: 4170.13\n",
      "episode #9 reward: 3942.84\n",
      "episode #10 reward: 4111.22\n",
      "episode #11 reward: 3999.71\n",
      "episode #12 reward: 4050.97\n",
      "episode #13 reward: 4143.10\n",
      "episode #14 reward: 4035.59\n",
      "episode #15 reward: 4156.98\n",
      "episode #16 reward: 4205.78\n",
      "episode #17 reward: 4093.63\n",
      "episode #18 reward: 3919.64\n",
      "episode #19 reward: 4166.09\n",
      "\n",
      " score: 4083.38 +- 110.10\n"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "n_trajectory=20\n",
    "for i in range(n_trajectory):\n",
    "    stats=play(env, policy, is_close=True, is_render=False)\n",
    "    rewards=stats['reward']\n",
    "    print(f'episode #{i} reward: {rewards:0.2f}')\n",
    "    scores.append(rewards)\n",
    "\n",
    "print(f'\\n score: {np.mean(scores):0.2f} +- {np.std(scores):0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imitation-dice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5a5c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297307dd-4476-44b7-ac81-3bc6657819f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/anaconda3/lib/python3.9/site-packages/botocore/httpsession.py:34: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.common.policies  import ActorCriticPolicy, ActorCriticCnnPolicy\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ce877",
   "metadata": {},
   "source": [
    "### Using SAC Trained Model\n",
    "* downloaded from https://huggingface.co/sb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a996249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6a28f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_trajectory(env, policy_net, n_trajectory=20, epsilon=0.0):\n",
    "    trajectories=[] \n",
    "    scores=[]\n",
    "    for episode in range(n_trajectory):\n",
    "        state,info = env.reset()\n",
    "        score = 0 \n",
    "        states=[]\n",
    "        actions=[]\n",
    "        rewards=[]\n",
    "        while True:\n",
    "            if epsilon==0:\n",
    "                action, _states = policy_net.predict(state, deterministic=True)\n",
    "            else:\n",
    "                if np.random.random() > (1-epsilon):\n",
    "                    action=env.action_space.sample() \n",
    "                else:\n",
    "                    action, _states = policy_net.predict(state, deterministic=True)\n",
    "            \n",
    "            next_state, reward, done,s, _ = env.step(action)\n",
    "            score+=reward\n",
    "             \n",
    "            states.append(state)\n",
    "            actions.append(action)\n",
    "            rewards.append(reward)\n",
    "            state = next_state \n",
    "            if done or s:  \n",
    "                scores.append(score)\n",
    "                break\n",
    "        \n",
    "        states=np.vstack(states)\n",
    "        actions=np.vstack(actions)\n",
    "        rewards=np.vstack(rewards)\n",
    "        trajectories.append((states, actions, rewards))  \n",
    "        if episode % 1 == 0:\n",
    "            print('{} episode score is {:.2f}'.format(episode, score))\n",
    "    env.close()\n",
    "    return scores, trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc21c0c",
   "metadata": {},
   "source": [
    "### Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "412d3bf2-b358-46cc-b510-c4095468574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath= \"trained_models/sb3_sac_Ant-v3.zip\"\n",
    "model=SAC.load(savepath, print_system_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5843b0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='Ant-v3' \n",
    "env_t = gym.make(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b889b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting trajectories ...\n",
      "0 episode score is 5246.79\n",
      "1 episode score is 3756.22\n",
      "2 episode score is 4987.11\n",
      "3 episode score is 5392.41\n",
      "4 episode score is 5097.51\n",
      "5 episode score is 5185.53\n",
      "6 episode score is 5309.34\n",
      "7 episode score is 5258.45\n",
      "8 episode score is 5468.29\n",
      "9 episode score is 4914.24\n",
      "mean score: 5061.589123630422\n"
     ]
    }
   ],
   "source": [
    "print('collecting trajectories ...')\n",
    "n_trajectory=10\n",
    "scores, trajectories = collect_trajectory(env_t, model, n_trajectory)\n",
    "mean=np.mean(scores)\n",
    "print('mean score:', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb301bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving  expert_data/Ant-v3_10_5061.pkl\n",
      "trajectories saved.\n"
     ]
    }
   ],
   "source": [
    "filename=f\"expert_data/{env_name}_{n_trajectory}_{int(mean)}.pkl\"\n",
    "print('saving ',filename)\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(trajectories, f)\n",
    "print('trajectories saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd177b-6152-4087-9294-b8a28d9024ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c5cdd63",
   "metadata": {},
   "source": [
    "### Halfcheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1884a496-1314-4f2a-9f1d-4e8bb8093522",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='HalfCheetah-v3' \n",
    "env_t = gym.make(env_name)\n",
    "\n",
    "savepath= \"trained_models/sb3_sac_HalfCheetah-v3.zip\"\n",
    "model=SAC.load(savepath, print_system_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9fc110-ef93-40b8-abdd-b919e19c047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting trajectories ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 episode score is 9529.82\n",
      "1 episode score is 9443.23\n",
      "2 episode score is 9528.88\n",
      "3 episode score is 9465.52\n",
      "4 episode score is 9413.04\n",
      "5 episode score is 9401.77\n",
      "6 episode score is 9578.25\n",
      "7 episode score is 9475.94\n",
      "8 episode score is 9473.76\n",
      "9 episode score is 9459.59\n",
      "10 episode score is 9657.36\n",
      "11 episode score is 9571.92\n",
      "12 episode score is 9525.01\n",
      "13 episode score is 9504.80\n",
      "14 episode score is 9738.49\n",
      "15 episode score is 9489.50\n",
      "16 episode score is 9603.78\n",
      "17 episode score is 9487.93\n",
      "18 episode score is 9312.35\n",
      "19 episode score is 9559.39\n",
      "20 episode score is 9391.63\n",
      "21 episode score is 9451.26\n",
      "22 episode score is 9502.53\n",
      "23 episode score is 9419.64\n",
      "24 episode score is 9478.82\n",
      "25 episode score is 9433.41\n",
      "26 episode score is 9500.71\n",
      "27 episode score is 9497.89\n",
      "28 episode score is 9557.21\n",
      "29 episode score is 9482.79\n",
      "30 episode score is 9500.97\n",
      "31 episode score is 9599.10\n",
      "32 episode score is 9564.33\n",
      "33 episode score is 9541.36\n",
      "34 episode score is 9460.36\n",
      "35 episode score is 9524.60\n",
      "36 episode score is 9438.34\n",
      "37 episode score is 9767.93\n",
      "38 episode score is 9691.80\n",
      "39 episode score is 9740.56\n",
      "40 episode score is 9425.05\n",
      "41 episode score is 9489.80\n",
      "42 episode score is 9519.48\n",
      "43 episode score is 9501.54\n",
      "44 episode score is 9486.75\n",
      "45 episode score is 9692.86\n",
      "46 episode score is 9573.38\n",
      "47 episode score is 9565.15\n",
      "48 episode score is 9608.62\n",
      "49 episode score is 9416.10\n",
      "mean score: 9520.88634373286\n"
     ]
    }
   ],
   "source": [
    "print('collecting trajectories ...')\n",
    "n_trajectory=50\n",
    "scores, trajectories = collect_trajectory(env_t, model, n_trajectory)\n",
    "mean=np.mean(scores)\n",
    "print('mean score:', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c88c16-469d-4afa-aac5-3765b99eb6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving  expert_data/HalfCheetah-v3_50_9520.pkl\n",
      "trajectories saved.\n"
     ]
    }
   ],
   "source": [
    "filename=f\"expert_data/{env_name}_{n_trajectory}_{int(mean)}.pkl\"\n",
    "print('saving ',filename)\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(trajectories, f)\n",
    "print('trajectories saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8307862-c387-4b6d-b247-368c20d6873a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7ba79f9",
   "metadata": {},
   "source": [
    "### Humanoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5db7d70-3159-4128-b980-c6a22223fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name='Humanoid-v3' \n",
    "env_t = gym.make(env_name)\n",
    "\n",
    "savepath= \"trained_models/sb3_sac_Humanoid-v3.zip\"\n",
    "model=SAC.load(savepath, print_system_info=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd967178-d12b-42c0-8b87-af4558c27c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting trajectories ...\n",
      "0 episode score is 6260.53\n",
      "1 episode score is 6256.61\n",
      "2 episode score is 6253.19\n",
      "3 episode score is 6228.46\n",
      "4 episode score is 6252.08\n",
      "5 episode score is 6233.50\n",
      "6 episode score is 6282.12\n",
      "7 episode score is 6257.20\n",
      "8 episode score is 6294.81\n",
      "9 episode score is 6282.26\n",
      "10 episode score is 6292.18\n",
      "11 episode score is 6212.32\n",
      "12 episode score is 6312.45\n",
      "13 episode score is 6237.54\n",
      "14 episode score is 6282.81\n",
      "15 episode score is 6272.98\n",
      "16 episode score is 6277.93\n",
      "17 episode score is 6240.83\n",
      "18 episode score is 6255.95\n",
      "19 episode score is 6274.40\n",
      "20 episode score is 6246.75\n",
      "21 episode score is 6226.93\n",
      "22 episode score is 6235.50\n",
      "23 episode score is 6265.73\n",
      "24 episode score is 6267.14\n",
      "25 episode score is 6255.98\n",
      "26 episode score is 6256.06\n",
      "27 episode score is 6229.69\n",
      "28 episode score is 6296.29\n",
      "29 episode score is 6235.81\n",
      "30 episode score is 6266.86\n",
      "31 episode score is 6267.82\n",
      "32 episode score is 6225.71\n",
      "33 episode score is 6273.90\n",
      "34 episode score is 6281.40\n",
      "35 episode score is 6283.65\n",
      "36 episode score is 6282.40\n",
      "37 episode score is 6268.04\n",
      "38 episode score is 6271.46\n",
      "39 episode score is 6280.09\n",
      "40 episode score is 6258.03\n",
      "41 episode score is 6249.87\n",
      "42 episode score is 6319.15\n",
      "43 episode score is 6256.38\n",
      "44 episode score is 6241.46\n",
      "45 episode score is 6246.90\n",
      "46 episode score is 6236.89\n",
      "47 episode score is 6260.15\n",
      "48 episode score is 6260.37\n",
      "49 episode score is 6247.99\n",
      "mean score: 6261.091739434408\n"
     ]
    }
   ],
   "source": [
    "print('collecting trajectories ...')\n",
    "n_trajectory=50\n",
    "scores, trajectories = collect_trajectory(env_t, model, n_trajectory)\n",
    "mean=np.mean(scores)\n",
    "print('mean score:', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7cc4ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving  expert_data/Humanoid-v3_50_6261.pkl\n",
      "trajectories saved.\n"
     ]
    }
   ],
   "source": [
    "filename=f\"expert_data/{env_name}_{n_trajectory}_{int(mean)}.pkl\"\n",
    "print('saving ',filename)\n",
    "\n",
    "with open(filename, 'wb') as f:\n",
    "    pickle.dump(trajectories, f)\n",
    "print('trajectories saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84b53c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7324cc46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff90d31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048b874-1d90-4af4-9dc9-f75a11918812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

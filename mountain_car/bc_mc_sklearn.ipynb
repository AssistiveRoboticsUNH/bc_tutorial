{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b86c65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "from matplotlib import pyplot as plt\n",
    "import gym\n",
    "import pickle \n",
    " \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18064b43",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216e6cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trajectories: 10\n"
     ]
    }
   ],
   "source": [
    "# data_path = \"expert_data/human_demos_4_-111.0.pkl\"\n",
    "data_path = \"expert_data/human_demos_10_-115.0.pkl\"\n",
    "# data_path = \"expert_data/human_demos_20_-113.0.pkl\"\n",
    "\n",
    "with open(data_path, 'rb') as f:\n",
    "    trajs = pickle.load(f)\n",
    "\n",
    "print(f\"Number of trajectories: {len(trajs)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886d7adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1138, 2), (1138,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states=[]\n",
    "actions=[]\n",
    "for traj in trajs:\n",
    "    for state,action in traj:\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "\n",
    "states=np.array(states)\n",
    "actions=np.array(actions)\n",
    "\n",
    "states.shape,actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deec36d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = np.max(actions)+1 \n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5996a6f5",
   "metadata": {},
   "source": [
    "### Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136c12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistice Regression is a linear model that does not work well with non-linear data\n",
    "# model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "# model.fit(states, actions)\n",
    "# model.score(states, actions)  #0.7504393673110721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394524cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will use random forest instead.\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "model.fit(states, actions)\n",
    "model.score(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340550b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e5f2c7",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dedd7a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name='MountainCar-v0'\n",
    "env = gym.make(env_name)\n",
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a983aba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7358e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_an_episode(env_name, model, render=False, max_step=500):\n",
    "     \n",
    "    if render:\n",
    "        env=gym.make(env_name, render_mode='human')\n",
    "    else:\n",
    "        env = gym.make(env_name)\n",
    "    total_reward=0  \n",
    "    state,_=env.reset() \n",
    "    for i in range(max_step):\n",
    "        if render: env.render()\n",
    "        action=model.predict([state])[0]\n",
    "        next_state,reward,done,trunc,info=env.step( action )\n",
    "        total_reward+=reward\n",
    "        state=next_state\n",
    "        if done or trunc: break \n",
    "            \n",
    "    env.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbce2a",
   "metadata": {},
   "source": [
    "### Single rollout (pop-up window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6302dd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-159.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r=play_an_episode(env_name, model, render=True)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8b232",
   "metadata": {},
   "source": [
    "### mean reward over rollouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "961c548c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0, reward: -90.0\n",
      "episode 1, reward: -161.0\n",
      "episode 2, reward: -83.0\n",
      "episode 3, reward: -166.0\n",
      "episode 4, reward: -143.0\n",
      "episode 5, reward: -145.0\n",
      "episode 6, reward: -177.0\n",
      "episode 7, reward: -183.0\n",
      "episode 8, reward: -146.0\n",
      "episode 9, reward: -166.0\n",
      "episode 10, reward: -84.0\n",
      "episode 11, reward: -85.0\n",
      "episode 12, reward: -182.0\n",
      "episode 13, reward: -159.0\n",
      "episode 14, reward: -91.0\n",
      "episode 15, reward: -166.0\n",
      "episode 16, reward: -167.0\n",
      "episode 17, reward: -97.0\n",
      "episode 18, reward: -92.0\n",
      "episode 19, reward: -156.0\n",
      "\n",
      "reward: -136.95 +- 36.84\n"
     ]
    }
   ],
   "source": [
    "rewards=[]\n",
    "n=20\n",
    "for i in range(n):\n",
    "    r=play_an_episode(env_name, model)\n",
    "    rewards.append(r)\n",
    "    print(f'episode {i}, reward: {r}')\n",
    "\n",
    "r_mean=np.mean(rewards)\n",
    "r_std=np.std(rewards)\n",
    "\n",
    "print(f'\\nreward: {r_mean:0.2f} +- {r_std:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01923e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada01545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc10200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01232893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
